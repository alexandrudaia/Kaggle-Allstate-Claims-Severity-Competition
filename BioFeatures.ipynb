{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "import numpy as np\n",
    "import  heapq\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score,StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('trainNumericEnergies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv('testNumericEnergies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188318, 133)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125546, 132)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainvec=np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testvec=np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PatternCount(text,pattern):\n",
    "    \"\"\"for  a  string   : 'ababcbcdcd' returns   number of occurences  of  cd  in string\"\"\"\n",
    "    count=0\n",
    "    for i in (range(0,((len(text))-len(pattern))+1)):\n",
    " \n",
    "       \n",
    "        if text[i:i+len(pattern)]==pattern:\n",
    "            count+=1\n",
    "            \n",
    "    \n",
    "    return count\n",
    "def   frequentWords(text,k):\n",
    "    FrequentPatterns=[]\n",
    "    count=[]\n",
    "    for i in range((len(text)-k)+1):\n",
    "        \n",
    "        pattern=text[i:i+k]\n",
    " \n",
    "        if not pattern==pattern[::-1]:\n",
    "          \n",
    "            count.append(PatternCount(text,pattern))\n",
    "    maximum=max(count)\n",
    " \n",
    "    for i in range((len(text)-k)+1):\n",
    "        pattern=text[i:i+k]\n",
    "        if not pattern==pattern[::-1]:\n",
    "            if PatternCount(text,pattern)==maximum :\n",
    "                FrequentPatterns.append(text[i:i+k])\n",
    "             \n",
    "    return((set(FrequentPatterns),maximum))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1=\"0001\"\n",
    "string1==string1[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catTrain=trainvec[:,1:117].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catTest=testvec[:,1:117].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'211122111111111111111111111111111111211111111111121111111111111111111111211142244223222111214235512911245107131071124951173'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "i=0\n",
    "\n",
    "L=list(catTrain[13,:])\n",
    "text=\"\".join(str(x) for x in L)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'111111112', '111111121', '111111211', '111112111', '211111111'}, 3)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequentWords(text,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  kin_energy(random_vec):\n",
    "    \"\"\"return    kinetic  energy  of   random vector represented    as   (n,) dimmensional  array\"\"\"\n",
    "    freq=np.unique(random_vec,return_counts=True)\n",
    "    prob=freq[1]/random_vec.shape[0]\n",
    "    energy=np.sum(prob**2)\n",
    "    return  energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n"
     ]
    }
   ],
   "source": [
    "new_feat=[]\n",
    "max_freq=[]\n",
    " \n",
    "length=[]\n",
    "kinetic=[]\n",
    " \n",
    "for  i in range(0,train.shape[0]):\n",
    "    \n",
    " \n",
    "    current_row=list(catTrain[i,:])\n",
    "    text=\"\".join(str(x) for x in current_row)\n",
    "    derived=frequentWords(text,2)\n",
    "    new_feat.append(derived[0])\n",
    "    max_freq.append(derived[1])\n",
    "    length.append(len(derived[0]))\n",
    "    ##########do    things  for kinetic  :\n",
    "    a=list(new_feat[i])\n",
    "    b=[list(map(int,str(i))) for  i in a]\n",
    "    c=[item for sublist in b for item in sublist]\n",
    "    c=np.array(c)\n",
    "    kinetic.append(kin_energy(c))\n",
    "    if i%10000==0:\n",
    "        print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"max\"]=np.array(max_freq)\n",
    "train['l']=length\n",
    "train['energy']=kinetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  7.01300000e+03,   7.15230000e+04,   3.89380000e+04,\n",
       "          4.98890000e+04,   1.07690000e+04,   8.27000000e+03,\n",
       "          1.65800000e+03,   1.68000000e+02,   8.00000000e+01,\n",
       "          1.00000000e+01]),\n",
       " array([  2. ,   3.6,   5.2,   6.8,   8.4,  10. ,  11.6,  13.2,  14.8,\n",
       "         16.4,  18. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f433fc3cba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import  matplotlib \n",
    "from   matplotlib import pyplot  as plt\n",
    "%matplotlib inline\n",
    "plt.hist(np.array(max_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "new_feat=[]\n",
    "max_freq=[]\n",
    " \n",
    "length=[]\n",
    "kinetic=[]\n",
    " \n",
    "for  i in range(0,test.shape[0]):\n",
    " \n",
    "    current_row=list(catTest[i,:])\n",
    "    text=\"\".join(str(x) for x in current_row)\n",
    "    derived=frequentWords(text,2)\n",
    "    new_feat.append(derived[0])\n",
    "    max_freq.append(derived[1])\n",
    "    length.append(len(derived[0]))\n",
    "    ##########do    things  for kinetic  :\n",
    "    a=list(new_feat[i])\n",
    "    b=[list(map(int,str(i))) for  i in a]\n",
    "    c=[item for sublist in b for item in sublist]\n",
    "    c=np.array(c)\n",
    "    kinetic.append(kin_energy(c))\n",
    "    if i%10000==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[\"max\"]=np.array(max_freq)\n",
    "test['l']=length\n",
    "test['energy']=kinetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('testBio.csv',index=False)\n",
    "train.to_csv('trainBio.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 or 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "from __future__ import division\n",
    "import pandas as pd \n",
    "import  random as random\n",
    "import numpy as np\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import heapq\n",
    "class BadErrorTreshold(Exception):\n",
    "    pass\n",
    "class ChooseCorrectClass(Exception):\n",
    "    print('1 or 0')\n",
    "class EnsembleRegressors(BaseEstimator):\n",
    "    ''''\n",
    "    ensembleRegressor is a class of ensembles generated by a  fix number of  iterations.This class is abstract \n",
    "    meaning  it  is not possible  to create instances  of it.,,stochasticLearning''  has interface  role. '''\n",
    "    def __init__(self,regressors,sampling,iterations,test,X,y):\n",
    "        ''''intialize ensemble with  near all  parameters- see that   some of them are  intialized  by other methods'''\n",
    "        self.test=test#final test set\n",
    "        self.X=X#original train features\n",
    "        self.y=y#original train outcome\n",
    "        self.iterations=iterations#number of  iterations in the  stochastic ensemble\n",
    "        self.regressors=regressors#ensemble models  for  each iteration\n",
    "        self.sampling=sampling#dropout(cv) ratio-percentage\n",
    "        self.randomIndexes=[ [] for iter in range(self.iterations)]#filled in with random dropout  by getStochasticDataSets()\n",
    "        self.error=[]#error for  each averaged iteration\n",
    "        self.error_after_optimization=[]\n",
    "        self.stochasticPredictions=[ [] for  prediction in range(self.iterations)]#predictions on random drop outs\n",
    "        self.finalPredictions=[ [] for  prediction in range(self.iterations)]#final predictions=> thi are either averaged or optimized\n",
    "        self.x_train=[]#his   next  4 rows are intialized  by getStochasticDataSets() according to random chunks\n",
    "        self.y_train=[]\n",
    "        self.x_test=[]\n",
    "        self.y_test=[]\n",
    "        \n",
    "    def returnError(self):\n",
    "        '''returns : error for  each iteration-just like cross-validation'''\n",
    "        return self.error\n",
    "    \n",
    "    def returnRandomIndexes(self):\n",
    "        '''returns: random  indexes  for  each dropout'''\n",
    "        return self.randomIndexes\n",
    "    \n",
    "    def returnstochasticPredictions(self):\n",
    "        '''returns:predictions  on random dropous'''\n",
    "        return self.stochasticPredictions\n",
    "    \n",
    "    def getStochasticDataSets(self):\n",
    "        '''\n",
    "        For some  potentially  iteration creates a random  idx variable representing the index  for random  dropout.\n",
    "        Splits the train in  train/test(x_train,y_train,features and outcome for cross val train-x_test,y_test for cross_val test\n",
    "        .Updated this train-test  variables with corresponding  values.See that  the initial vales are empty in the __init__.\n",
    "        returns: idx(index of  dropout rows).\n",
    "        \n",
    "        '''    \n",
    "        x_train, x_test, y_train, y_test = train_test_split(self.X, self.y, test_size=self.sampling)\n",
    "        self.x_train=x_train\n",
    "        self.x_test=x_test\n",
    "        self.y_train=y_train\n",
    "        self.y_test=y_test\n",
    "        #idx=np.random.choice(range(0,self.X.shape[0]),self.sampling)\n",
    "        #self.x_test=self.X[idx]\n",
    "        #self.y_test=self.y[idx]\n",
    "        #idx_learn=set(range(0,(self.X).shape[0]))-set(idx)\n",
    "        #self.x_train=self.X[list(idx_learn)]\n",
    "        #self.y_train=self.y[list(idx_learn)]\n",
    "        #return  idx\n",
    "    \n",
    "    def training(self,i):\n",
    "        ''''\n",
    "        For a  particular iteration ,,i''  calls getStochasticDataSets() method.In this was the randomIndexes feature is\n",
    "        fiiled with corresponding index dropouts at position ,,i''.Since train/test new data sets according to cross validation\n",
    "        are   filled  by getStochasticDataSets()  independet  of iteration number , this data sets will update for each new iter.\n",
    "        performmed in stochasticLearning().'''\n",
    "        \n",
    "        self.randomIndexes[i]=self.getStochasticDataSets()\n",
    "        self.regressors_=[]#here  are appended fitted regressors\n",
    "        for regressor  in self.regressors:\n",
    "            trained_regressor=clone(regressor).fit(self.x_train,self.y_train)#clone from sklearn-base-clones without data\n",
    "            self.regressors_.append(trained_regressor)\n",
    "        return self\n",
    "    \n",
    "    def getFinalPrediction(self,errorTreshold):\n",
    "       raise NotImplementedError###averages models  according to best top prediction  trehsold  with different implementantions\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    def stochasticLearning(self):\n",
    "         raise NotImplementedError#Since EnsemebleRegressors class is abstract this will act  as an interface\n",
    "                                  #and will be implemented   by  this  EnsembleRegressors sublclasses  for averaging and\n",
    "                                  #weighted average\n",
    "    \n",
    "        \n",
    "\n",
    "class AveragingModels(EnsembleRegressors):\n",
    "    '''Inherits everything from EnsembleRegressors  class and implements stochastiLearning method  averaging models \n",
    "    for each iteration'''\n",
    " \n",
    "    def stochasticLearning(self):\n",
    "        \n",
    "        \n",
    "        for iter in range(self.iterations):\n",
    "            print('Stochastic Iteration number ',iter)\n",
    "            self.training(iter)\n",
    "            self.stochasticPredictions[iter]=[regressor.predict(self.x_test) for regressor in  self.regressors_]#updated  stochastic\n",
    "            #prediction with array different shaped  predictions  at position ,,iter''\n",
    "            sum=0\n",
    "            for pred in range(len(self.stochasticPredictions[iter])):\n",
    "                self.stochasticPredictions[iter][pred]=self.stochasticPredictions[iter][pred].reshape(self.x_test.shape[0],1)\n",
    "                #reshapes prediction  in list at position iter to have the same size of  fata according to prediction\n",
    "                sum=sum+self.stochasticPredictions[iter][pred]\n",
    "            avg=sum/len(self.regressors)\n",
    "            self.stochasticPredictions[iter]=avg#replaces corresponding list  predictions with their average\n",
    "            self.error.append(mean_absolute_error(self.y_test,np.array(avg))) \n",
    "        \n",
    "            #make final averaged predictions\n",
    "            self.finalPredictions[iter]=[regressor.predict(self.test) for regressor in self.regressors_]#updated final predictions\n",
    "            sum=0\n",
    "            for pred in range(len(self.finalPredictions[iter])):\n",
    "                self.finalPredictions[iter][pred]=self.finalPredictions[iter][pred].reshape(self.test.shape[0],1)\n",
    "                sum=sum+self.finalPredictions[iter][pred]\n",
    "            avg=sum/len(self.regressors)\n",
    "            self.finalPredictions[iter]=avg\n",
    "            '''For each iteration : fills prediction  in stochasticPrediction(initial empty in initialize) with corresponding\n",
    "         list of arrays of predictions at position iter.For loops this position in the list  to reshape the  dropout prediction\n",
    "         arrays.Since  is is  for looping average of predictions are made in same for loop.Also  appends  error between  dropout\n",
    "         ground truth outcome values and predicted droputs'''\n",
    "    def getFinalPrediction(self,errorTreshold):\n",
    "        if (errorTreshold<=self.iterations and errorTreshold>0):\n",
    "            \n",
    "            topErrorIndex=heapq.nsmallest(errorTreshold, range(len(self.error)), self.error.__getitem__)\n",
    "            finalAvg=0\n",
    "            for topError in topErrorIndex:\n",
    "                finalAvg=finalAvg+self.finalPredictions[topError]\n",
    "            finalAvg=(finalAvg)/float(len(topErrorIndex))\n",
    "            return finalAvg\n",
    "        else:\n",
    "            raise BadErrorTreshold\n",
    "       \n",
    "       \n",
    "    \n",
    "                                                \n",
    "class OptimizedAverage(EnsembleRegressors):\n",
    "    '''https://www.kaggle.com/hsperr/otto-group-product-classification-challenge/finding-ensamble-weights'''\n",
    "    \n",
    "    '''This subclass of  EnsembleRegressors inherits   everything from base class.The  implementantion of stochasticLearningis\n",
    "    is different meaning it   optimize  weights  of the learnersin order to minimize the  loss metric on random dropout...'''\n",
    "    \n",
    "    #def __init__(self,regressors,sampling,iterations,test,X,y):\n",
    "    #    '''inherits  everything  from EnsemebleRegressors even init  with  mention it  creates  a new  variable for error \n",
    "    #    after optimization'''\n",
    "        \n",
    "    # #   EnsembleRegressors.__init__(self,regressors,sampling,iterations,test,X,y)\n",
    "    #    self.error_after_optimization=[]#error  for weighted average optimization\n",
    "   \n",
    " \n",
    "    def stochasticLearning(self):\n",
    " \n",
    "        from scipy.optimize import minimize   \n",
    "        ''''Computes also  average and weighted average in order to  compare the errors  before  and after to see gains'''\n",
    "        \n",
    "        for iter in range(self.iterations):\n",
    "            print('Stochastic Iteration number ',iter)\n",
    "            self.training(iter)\n",
    "            self.stochasticPredictions[iter]=[regressor.predict(self.x_test) for regressor in  self.regressors_]#updated  stochastic\n",
    "            #prediction with array different shaped  predictions  at position ,,iter''\n",
    "            sum=0\n",
    "            for pred in range(len(self.stochasticPredictions[iter])):\n",
    "                self.stochasticPredictions[iter][pred]=self.stochasticPredictions[iter][pred].reshape(self.x_test.shape[0],1)\n",
    "                #reshapes prediction  in list at position iter to have the same size of  fata according to prediction\n",
    "                sum=sum+self.stochasticPredictions[iter][pred]\n",
    "            avg=sum/len(self.regressors)\n",
    "            self.error.append(mean_absolute_error(self.y_test,np.array(avg))) \n",
    "            predictions=self.stochasticPredictions[iter]\n",
    "            \n",
    "            def loss_function(weights):\n",
    "                final_prediction=0\n",
    "                for weight,prediction in  zip(weights,predictions):\n",
    "                    final_prediction+=weight*prediction\n",
    "                return mean_squared_error(self.y_test,final_prediction)\n",
    "            starting_values=[0.1]*len(predictions)\n",
    "            cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n",
    "            bounds = [(0,1)]*len(predictions)\n",
    "            res = minimize(loss_function, starting_values, method='SLSQP', bounds=bounds)\n",
    "            print('Ensamble Score: {best_score}'.format(best_score=res['fun']))\n",
    "            print('Best Weights: {weights}'.format(weights=res['x']))\n",
    "            print(res['fun'])\n",
    "            pounds=res['x']\n",
    "            yhat=0\n",
    "            for i in range(len(predictions)):\n",
    "                yhat+=predictions[i]*pounds[i]\n",
    "            self.error_after_optimization.append(mean_squared_error(self.y_test,np.array(yhat)))\n",
    "            self.finalPredictions[iter]=[regressor.predict(self.test) for regressor in self.regressors_]#updated final predictions\n",
    "            test_yhat=0\n",
    "            for pred in range(len(self.finalPredictions[iter])):\n",
    "                self.finalPredictions[iter][pred]=self.finalPredictions[iter][pred].reshape(self.test.shape[0],1)\n",
    "                test_yhat+=self.finalPredictions[iter][pred]*pounds[pred]\n",
    "            self.finalPredictions[iter]=test_yhat\n",
    "        \n",
    "    def getFinalPrediction(self,errorTreshold):\n",
    "        \n",
    "        '''makes  average  of  final predictions based on top error  treshold-errorTreshold <=number of iterations'''\n",
    "       \n",
    "        errorType=input(' Choose  : 1 for optim error - Choose: 2 for average error retrieveing optimized prediction by error')\n",
    "        if errorType==1:\n",
    "            err=self.error_after_optimization\n",
    "        elif erroType==2:\n",
    "            err=self.error\n",
    "        else :\n",
    "            raise BadErrorTreshold\n",
    "            \n",
    "        if (errorTreshold<=self.iterations and errorTreshold>0):\n",
    "            topErrorIndex=heapq.nsmallest(errorTreshold, range(len(err)),err.__getitem__)\n",
    "            finalAvg=0\n",
    "            for topError in topErrorIndex:\n",
    "                finalAvg=finalAvg+self.finalPredictions[topError]\n",
    "            finalAvg=(finalAvg)/float(len(topErrorIndex))\n",
    "            return finalAvg\n",
    "        else:\n",
    "            raise BadErrorTreshold\n",
    "            \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import  xgboost   as xgb\n",
    "xgb1=xgb.XGBRegressor(n_estimators=150)\n",
    "xgb2=xgb.XGBRegressor(n_estimators=200)\n",
    "xgb3=xgb.XGBRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Iteration number  0\n",
      "Ensamble Score: 14645854.712605556\n",
      "Best Weights: [ 0.1  0.1]\n",
      "14645854.7126\n",
      "Stochastic Iteration number  1\n",
      "Ensamble Score: 7418715.113540363\n",
      "Best Weights: [ 1.  1.]\n",
      "7418715.11354\n",
      "Stochastic Iteration number  2\n",
      "Ensamble Score: 14435252.505986962\n",
      "Best Weights: [ 0.1  0.1]\n",
      "14435252.506\n"
     ]
    }
   ],
   "source": [
    "a=OptimizedAverage([xgb1,xgb2],0.2,3,testvec,trainvec,y)\n",
    "a.stochasticLearning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1412.507528224611, 1401.5218280826589, 1394.9941264148797]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14645854.712605556, 7418715.1135403626, 14435252.505986962]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.error_after_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=a.getFinalPrediction(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import  matplotlib\n",
    "from matplotlib  import  pyplot as plt\n",
    "plt.hist(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub['loss']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('sub1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
